# -*- coding: utf-8 -*-
"""Submission1x.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nnNA38dLk1DPyL1EYq9WkC9CIf3lYYtb
"""

# Import dataset yang akan digunakan yaitu 'bbc-text.csv' (source: https://www.kaggle.com/balatmak/newsgroup20bbcnews?select=bbc-text.csv)

import pandas as pd
news_df = pd.read_csv('bbc-text.csv')
news_df

# Menggunakan One Hot Encoding untuk memisahkan data kolom 'category'

category = pd.get_dummies(news_df['category'])
news_fixed = pd.concat([news_df, category], axis=1)
news_fixed = news_fixed.drop(columns='category')
news_fixed

# Menggunakan values function agar bisa diproses oleh model

text = news_fixed['text'].values
label = news_fixed[['business', 'entertainment', 'politics', 'sport', 'tech']].values

# Train test split data

from sklearn.model_selection import train_test_split

text_train, text_test, label_train, label_test = train_test_split(text, label, test_size=0.2)

# Menggunakan text preprocessing tokenizer dan sequence preprocessing padsequences

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

train_sequences = tokenizer.texts_to_sequences(text_train)
test_sequences = tokenizer.texts_to_sequences(text_test)
 
train_padsequences = pad_sequences(train_sequences)
test_padsequences = pad_sequences(test_sequences)

# Menggunakan model sequential dengan menggunakan layers embedding, LSTM, dan Dense

import tensorflow
from tensorflow import keras
from tensorflow.keras import initializers

model = keras.Sequential([
                          keras.layers.Embedding(input_dim=5000, output_dim=16),
                          keras.layers.LSTM(64),
                          keras.layers.Dense(128, activation='relu'),
                          keras.layers.Dropout(0.5),
                          keras.layers.Dense(5, activation='softmax')
])

# Compile model

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Tambahkan fungsi calbacks on_epoch_end

class myCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nAkurasi Model dan Validation telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

# Fit model

hist = model.fit(
    train_padsequences,
    label_train,
    epochs=30,
    validation_data=(test_padsequences, label_test),
    verbose=2,
    callbacks=[callbacks]
)

# Membuat grafik plot loss dan akurasi train test

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Grafik Plot Akurasi Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='lower right')
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Grafik Plot Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='lower right')
plt.show()

